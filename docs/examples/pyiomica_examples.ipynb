{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/gmiaslab/pyiomica/master/pyiomica/data/PyIOmica.png?token=AKZGC3KSHJC4BEYKHRJ3D3C5HBZZC\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyIOmica\n",
    "import pyiomica as pio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of MathIOmica objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyiomica\\data\\ExampleData \n",
      "\n",
      "rnaExample: {'7': {('FAM138A', 'RNA'): (0, 'OK'), ('OR4F5', 'RNA'): (0, 'OK'), ('LOC729737', 'RNA'): (2.73998, 'OK'), ('DDX11L1', 'RNA'): (6.75461, 'OK'), ('WASH7P', 'RNA'): (11.8883, 'OK'), ('MIR6859-1', 'RNA'): (0.256318, 'OK'), ('OR4F16', 'RNA'): (0.0053034, 'OK'), ('LOC100132287', 'RNA'): (1.97164, 'OK'), ('LOC100133331', 'RNA'): (5.80254e-05, 'OK'), ('MIR6723', 'RNA'): (20.3672, 'OK'), ('OR4F29', 'RNA'): \t. . .\n",
      "\n",
      "proteinClassificationExample: {'SpikeMax': {('O14933', 'Protein'): ((0.4849004228596584, 0.050070636189644156, 0.5664473466604335, 0.30949242460233894, 0.23311633547831045, 0.5386852734130892, 0.03451527514359191), (-0.04912828102266407, 0.0, 0.047486747232116745, 0.05781001938939018, 0.0018554794650575278, 0.07692798803247838, 0.889969492713528, -0.05132183205490717, 0.08748941292339298, 0.040475366762846916, -0.1336772226107 \t. . .\n",
      "\n",
      "proteinTimeSeriesExample: {('A0AVT1', 'Protein'): (-0.20659318820947548, 0.0, 0.00940325600745479, -0.11002681881280515, -0.05719318431295019, 0.1969020264180568, 0.5311951869517098, 0.07384981442020351, -0.5337739620790529, 0.26082873245760485, 0.21703366523988002, 'Missing[]', -0.15708162036637413, -0.43507907967714743, -0.03798709370006283), ('A0FGR8', 'Protein'): (0.1560814138062252, 0.0, -0.1865886054264821, 0.0155952 \t. . .\n",
      "\n",
      "proteinExample: {'7': {('A0AVT1', 'Protein'): (0.937, 17), ('A0FGR8', 'Protein'): (1.073, 24), ('A0MZ66', 'Protein'): (1.059, 9), ('A1A4S6', 'Protein'): (1.03, 11), ('A1L0T0', 'Protein'): (1.268, 4), ('A1X283', 'Protein'): (1.277, 1), ('A2RRP1', 'Protein'): (0.977, 12), ('A2RTX5', 'Protein'): (1.351, 4), ('A2RUS2', 'Protein'): (1.017, 12), ('A3KMH1', 'Protein'): 'Missing[]', ('A3KN83', 'Protein'): (0.88, 1), ('A4 \t. . .\n",
      "\n",
      "metabolomicsPositiveModeExample: {'8': {(202.0329, 0.33260712, 'Meta'): ((263741, 276622, 337241), ('', '')), (174.0375, 0.33451426, 'Meta'): ((78435, 88529, 121073), ('', '')), (142.012, 0.3335833, 'Meta'): ((318908, 371272, 297537), ('', '')), (100.0009, 0.33358333, 'Meta'): ((42319, 35074, 34575), ('', '')), (81.9906, 0.33332258, 'Meta'): ((36822, 30341, 30344), ('', '')), (942.9842, 0.34920588, 'Meta'): ((160507, 132428, 1322 \t. . .\n",
      "\n",
      "metabolomicsNegativeModeExample: {'8': {(457.0024, 0.34764, 'Meta'): ((23444, 16317, 1), (' [ C16 H11 N9 S4, db=0.00, overall=47.55, mfg=95.11 ]', '')), (530.0453, 0.35665718, 'Meta'): ((24079, 27071, 27347), (' [ C23 H18 N2 O9 S2, db=0.00, overall=44.30, mfg=88.61 ]', '')), (694.0508, 0.3540571, 'Meta'): ((15664, 15419, 16108), (' [ C24 H18 N14 O4 S4, db=0.00, overall=41.90, mfg=83.80 ]', '')), (776.0537, 0.3550645, 'Meta'): ((1 \t. . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %load examplesImportMathiomicaObjects.py\n",
    "\n",
    "from pyiomica.utilityFunctions import readMathIOmicaData\n",
    "\n",
    "print(pio.ConstantPyIOmicaExamplesDirectory, '\\n')\n",
    "tempPath = pio.os.path.join(pio.ConstantPyIOmicaExamplesDirectory, 'MathIOmicaExamples')\n",
    "\n",
    "rnaExample = readMathIOmicaData(pio.os.path.join(tempPath, 'rnaExample'))\n",
    "print('rnaExample:', str(rnaExample)[:400], '\\t. . .\\n')\n",
    "\n",
    "proteinClassificationExample = readMathIOmicaData(pio.os.path.join(tempPath, 'proteinClassificationExample'))\n",
    "print('proteinClassificationExample:', str(proteinClassificationExample)[:400], '\\t. . .\\n')\n",
    "\n",
    "proteinTimeSeriesExample = readMathIOmicaData(pio.os.path.join(tempPath, 'proteinTimeSeriesExample'))\n",
    "print('proteinTimeSeriesExample:', str(proteinTimeSeriesExample)[:400], '\\t. . .\\n')\n",
    "\n",
    "proteinExample = readMathIOmicaData(pio.os.path.join(tempPath, 'proteinExample'))\n",
    "print('proteinExample:', str(proteinExample)[:400], '\\t. . .\\n')\n",
    "\n",
    "metabolomicsPositiveModeExample = readMathIOmicaData(pio.os.path.join(tempPath, 'metabolomicsPositiveModeExample'))\n",
    "print('metabolomicsPositiveModeExample:', str(metabolomicsPositiveModeExample)[:400], '\\t. . .\\n')\n",
    "\n",
    "metabolomicsNegativeModeExample = readMathIOmicaData(pio.os.path.join(tempPath, 'metabolomicsNegativeModeExample'))\n",
    "print('metabolomicsNegativeModeExample:', str(metabolomicsNegativeModeExample)[:400], '\\t. . .\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of GO Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/EnrichmentOutputDirectory/GOAnalysis/goExample1.xlsx\n",
      "Saved: results/EnrichmentOutputDirectory/GOAnalysis/analysisGOAssociation.xlsx\n",
      "Saved: results/EnrichmentOutputDirectory/GOAnalysis/analysisGOLabel.xlsx\n",
      "Saved: results/EnrichmentOutputDirectory/GOAnalysis/analysisGOMixed.xlsx\n",
      "Saved: results/EnrichmentOutputDirectory/GOAnalysis/analysisGOMixedMulti.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Domanskyi\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py:162: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return cls.__new__(cls, **d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/EnrichmentOutputDirectory/GOAnalysis/ExampleClusteringObjectGO.xlsx\n"
     ]
    }
   ],
   "source": [
    "# %load examplesGOAnalysis.py\n",
    "\n",
    "from pyiomica.enrichmentAnalyses import GOAnalysis, ExportEnrichmentReport\n",
    "from pyiomica import dataStorage as ds\n",
    "\n",
    "EnrichmentOutputDirectory = 'results/EnrichmentOutputDirectory/'\n",
    "\n",
    "#Let's do a GO analysis for a group of genes, annotated with their \"Gene Symbol\":\n",
    "goExample1 = GOAnalysis([\"TAB1\", \"TNFSF13B\", \"MALT1\", \"TIRAP\", \"CHUK\", \n",
    "                                \"TNFRSF13C\", \"PARP1\", \"CSNK2A1\", \"CSNK2A2\", \"CSNK2B\", \"LTBR\", \n",
    "                                \"LYN\", \"MYD88\", \"GADD45B\", \"ATM\", \"NFKB1\", \"NFKB2\", \"NFKBIA\", \n",
    "                                \"IRAK4\", \"PIAS4\", \"PLAU\"])\n",
    "\n",
    "ExportEnrichmentReport(goExample1, AppendString='goExample1', OutputDirectory=EnrichmentOutputDirectory + 'GOAnalysis/')\n",
    "\n",
    "#The information can be computed for multiple groups, if these are provided as an association:\n",
    "analysisGOAssociation = GOAnalysis({\"Group1\": [\"C6orf57\", \"CD46\", \"DHX58\", \"HMGB3\", \"MAP3K5\", \"NFKB2\", \"NOS2\", \"PYCARD\", \"PYDC1\", \"SSC5D\"], \n",
    "                                                \"Group2\": [\"TAB1\", \"TNFSF13B\", \"MALT1\", \"TIRAP\", \"CHUK\", \"TNFRSF13C\", \"PARP1\", \"CSNK2A1\", \"CSNK2A2\", \"CSNK2B\", \"LTBR\", \n",
    "                                                            \"LYN\", \"MYD88\", \"GADD45B\", \"ATM\", \"NFKB1\", \"NFKB2\", \"NFKBIA\", \"IRAK4\", \"PIAS4\", \"PLAU\"]})\n",
    "\n",
    "ExportEnrichmentReport(analysisGOAssociation, AppendString='analysisGOAssociation', OutputDirectory=EnrichmentOutputDirectory + 'GOAnalysis/')\n",
    "\n",
    "#The data can be computed with or without a label. If labeled, the gene ID must be the first element for each ID provided. The data is in the form {ID,label}:\n",
    "analysisGOLabel = GOAnalysis([[\"C6orf57\", \"Protein\"], [\"CD46\", \"Protein\"], [\"DHX58\", \"Protein\"], [\"HMGB3\", \"Protein\"], [\"MAP3K5\", \"Protein\"], \n",
    "                                        [\"NFKB2\", \"Protein\"], [\"NOS2\", \"Protein\"], [\"PYCARD\", \"Protein\"], [\"PYDC1\",\"Protein\"], [\"SSC5D\", \"Protein\"]])\n",
    "\n",
    "ExportEnrichmentReport(analysisGOLabel, AppendString='analysisGOLabel', OutputDirectory=EnrichmentOutputDirectory + 'GOAnalysis/')\n",
    "\n",
    "#The data can be mixed, e.g. proteins and RNA with different labels:\n",
    "analysisGOMixed = GOAnalysis([[\"C6orf57\", \"Protein\"], [\"CD46\", \"Protein\"], [\"DHX58\", \"Protein\"], [\"HMGB3\", \"RNA\"], [\"HMGB3\", \"Protein\"], [\"MAP3K5\", \"Protein\"], \n",
    "                                        [\"NFKB2\", \"RNA\"], [\"NFKB2\", \"Protein\"], [\"NOS2\", \"RNA\"], [\"PYCARD\", \"RNA\"], [\"PYDC1\", \"Protein\"], [\"SSC5D\", \"Protein\"]])\n",
    "\n",
    "ExportEnrichmentReport(analysisGOMixed, AppendString='analysisGOMixed', OutputDirectory=EnrichmentOutputDirectory + 'GOAnalysis/')\n",
    "\n",
    "#We can instead treat the data as different by setting the MultipleList and MultipleListCorrection options:\n",
    "analysisGOMixedMulti = GOAnalysis([[\"C6orf57\", \"Protein\"], [\"CD46\", \"Protein\"], [\"DHX58\", \"Protein\"], [\"HMGB3\", \"RNA\"], [\"HMGB3\", \"Protein\"], [\"MAP3K5\", \"Protein\"], \n",
    "                                            [\"NFKB2\", \"RNA\"], [\"NFKB2\", \"Protein\"], [\"NOS2\", \"RNA\"], [\"PYCARD\", \"RNA\"], [\"PYDC1\", \"Protein\"], [\"SSC5D\", \"Protein\"]],\n",
    "                                            MultipleList=True, MultipleListCorrection='Automatic')\n",
    "\n",
    "ExportEnrichmentReport(analysisGOMixedMulti, AppendString='analysisGOMixedMulti', OutputDirectory=EnrichmentOutputDirectory + 'GOAnalysis/')\n",
    "\n",
    "#Let's consider an example from real protein data. We will use already clustered data, from the examples. Let's import the data:\n",
    "ExampleClusteringObject = ds.read(pio.os.path.join(pio.ConstantPyIOmicaExamplesDirectory, 'exampleClusteringObject_SLV_Delta_LAG1_Autocorr'))\n",
    "\n",
    "if not ExampleClusteringObject is None:\n",
    "    #We calculate the GOAnalysis for each group in each class:\n",
    "    ExampleClusteringObjectGO = GOAnalysis(ExampleClusteringObject, MultipleListCorrection='Automatic')\n",
    "\n",
    "    ExportEnrichmentReport(ExampleClusteringObjectGO, AppendString='ExampleClusteringObjectGO', OutputDirectory=EnrichmentOutputDirectory + 'GOAnalysis/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of KEGG Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results\\EnrichmentOutputDirectory\\KEGGAnalysis/keggExample1.xlsx\n",
      "Saved: results\\EnrichmentOutputDirectory\\KEGGAnalysis/analysisKEGGAssociation.xlsx\n",
      "Saved: results\\EnrichmentOutputDirectory\\KEGGAnalysis/analysisKEGGLabel.xlsx\n",
      "Saved: results\\EnrichmentOutputDirectory\\KEGGAnalysis/analysisKEGGNoLabel.xlsx\n",
      "Saved: results\\EnrichmentOutputDirectory\\KEGGAnalysis/analysisKEGGstrings.xlsx\n",
      "Saved: results\\EnrichmentOutputDirectory\\KEGGAnalysis/analysisKEGGMixed.xlsx\n",
      "Saved: results\\EnrichmentOutputDirectory\\KEGGAnalysis/analysisKEGGMixedMulti.xlsx\n",
      "Saved: results\\EnrichmentOutputDirectory\\KEGGAnalysis/compoundsExampleKEGG.xlsx\n",
      "Saved: results\\EnrichmentOutputDirectory\\KEGGAnalysis/multiOmicsDataKEGG.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Domanskyi\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py:162: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return cls.__new__(cls, **d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results\\EnrichmentOutputDirectory\\KEGGAnalysis/ExampleClusteringObject.xlsx\n"
     ]
    }
   ],
   "source": [
    "# %load examplesKEGGAnalysis.py\n",
    "\n",
    "from pyiomica.enrichmentAnalyses import KEGGAnalysis, ExportEnrichmentReport\n",
    "from pyiomica import dataStorage as ds\n",
    "\n",
    "EnrichmentOutputDirectory = pio.os.path.join('results', 'EnrichmentOutputDirectory', '')\n",
    "\n",
    "#Let's do a KEGG pathway analysis for a group of genes (most in the NFKB pathway), annotated with their \"Gene Symbol\":\n",
    "keggExample1 = KEGGAnalysis([\"TAB1\", \"TNFSF13B\", \"MALT1\", \"TIRAP\", \"CHUK\", \"TNFRSF13C\", \"PARP1\", \"CSNK2A1\", \"CSNK2A2\", \"CSNK2B\", \"LTBR\", \"LYN\", \"MYD88\", \n",
    "                                        \"GADD45B\", \"ATM\", \"NFKB1\", \"NFKB2\", \"NFKBIA\", \"IRAK4\", \"PIAS4\", \"PLAU\", \"POLR3B\", \"NME1\", \"CTPS1\", \"POLR3A\"])\n",
    "\n",
    "ExportEnrichmentReport(keggExample1, AppendString='keggExample1', OutputDirectory=EnrichmentOutputDirectory + 'KEGGAnalysis/')\n",
    "\n",
    "#The information can be computed for multiple groups, if these are provided as an association:\n",
    "analysisKEGGAssociation = KEGGAnalysis({\"Group1\": [\"C6orf57\", \"CD46\", \"DHX58\", \"HMGB3\", \"MAP3K5\", \"NFKB2\", \"NOS2\", \"PYCARD\", \"PYDC1\", \"SSC5D\"], \n",
    "                                                    \"Group2\": [\"TAB1\", \"TNFSF13B\", \"MALT1\", \"TIRAP\", \"CHUK\", \"TNFRSF13C\", \"PARP1\", \"CSNK2A1\", \"CSNK2A2\", \"CSNK2B\", \"LTBR\", \n",
    "                                                \"LYN\", \"MYD88\", \"GADD45B\", \"ATM\", \"NFKB1\", \"NFKB2\", \"NFKBIA\", \"IRAK4\", \"PIAS4\", \"PLAU\", \"POLR3B\", \"NME1\", \"CTPS1\", \"POLR3A\"]})\n",
    "        \n",
    "ExportEnrichmentReport(analysisKEGGAssociation, AppendString='analysisKEGGAssociation', OutputDirectory=EnrichmentOutputDirectory + 'KEGGAnalysis/')\n",
    "\n",
    "#The data can be computed with or without a label. If labeled, the gene ID must be the first element for each ID provided. The data is in the form {ID,label}:\n",
    "analysisKEGGLabel = KEGGAnalysis([[\"C6orf57\", \"Protein\"], [\"CD46\", \"Protein\"], [\"DHX58\", \"Protein\"], [\"HMGB3\", \"Protein\"], [\"MAP3K5\", \"Protein\"], \n",
    "                                            [\"NFKB2\", \"Protein\"], [\"NOS2\", \"Protein\"], [\"PYCARD\", \"Protein\"], [\"PYDC1\",\"Protein\"], [\"SSC5D\", \"Protein\"]])\n",
    "\n",
    "ExportEnrichmentReport(analysisKEGGLabel, AppendString='analysisKEGGLabel', OutputDirectory=EnrichmentOutputDirectory + 'KEGGAnalysis/')\n",
    "\n",
    "#The same result is obtained if IDs are enclosed in list brackets:\n",
    "analysisKEGGNoLabel = KEGGAnalysis([[\"C6orf57\"], [\"CD46\"], [\"DHX58\"], [\"HMGB3\"], [\"MAP3K5\"], [\"NFKB2\"], [\"NOS2\"], [\"PYCARD\"], [\"PYDC1\"], [\"SSC5D\"]])\n",
    "\n",
    "ExportEnrichmentReport(analysisKEGGNoLabel, AppendString='analysisKEGGNoLabel', OutputDirectory=EnrichmentOutputDirectory + 'KEGGAnalysis/')\n",
    "\n",
    "#The same result is obtained if IDs are input as strings:\n",
    "analysisKEGGstrings = KEGGAnalysis([\"C6orf57\", \"CD46\", \"DHX58\", \"HMGB3\", \"MAP3K5\", \"NFKB2\", \"NOS2\", \"PYCARD\", \"PYDC1\", \"SSC5D\"])\n",
    "\n",
    "ExportEnrichmentReport(analysisKEGGstrings, AppendString='analysisKEGGstrings', OutputDirectory=EnrichmentOutputDirectory + 'KEGGAnalysis/')\n",
    "\n",
    "#The data can be mixed, e.g. proteins and RNA with different labels:\n",
    "analysisKEGGMixed = KEGGAnalysis([[\"C6orf57\", \"Protein\"], [\"CD46\", \"Protein\"], [\"DHX58\", \"Protein\"], [\"HMGB3\", \"RNA\"], [\"HMGB3\", \"Protein\"], [\"MAP3K5\", \"Protein\"], \n",
    "                                            [\"NFKB2\", \"RNA\"], [\"NFKB2\", \"Protein\"], [\"NOS2\", \"RNA\"], [\"PYCARD\", \"RNA\"], [\"PYDC1\", \"Protein\"], [\"SSC5D\", \"Protein\"]])\n",
    "\n",
    "ExportEnrichmentReport(analysisKEGGMixed, AppendString='analysisKEGGMixed', OutputDirectory=EnrichmentOutputDirectory + 'KEGGAnalysis/')\n",
    "\n",
    "#The data in this case treated as originating from a single population. Protein and RNA labeled data for the same identifier are treated as equivalent.\n",
    "#We can instead treat the data as different by setting the MultipleList and MultipleListCorrection options:\n",
    "analysisKEGGMixedMulti = KEGGAnalysis([[\"C6orf57\", \"Protein\"], [\"CD46\", \"Protein\"], [\"DHX58\", \"Protein\"], [\"HMGB3\", \"RNA\"], [\"HMGB3\", \"Protein\"], [\"MAP3K5\", \"Protein\"], \n",
    "                                                [\"NFKB2\", \"RNA\"], [\"NFKB2\", \"Protein\"], [\"NOS2\", \"RNA\"], [\"PYCARD\", \"RNA\"], [\"PYDC1\", \"Protein\"], [\"SSC5D\", \"Protein\"]], \n",
    "                                                MultipleList=True, MultipleListCorrection='Automatic')\n",
    "\n",
    "ExportEnrichmentReport(analysisKEGGMixedMulti, AppendString='analysisKEGGMixedMulti', OutputDirectory=EnrichmentOutputDirectory + 'KEGGAnalysis/')\n",
    "\n",
    "#We can carry out a \"Molecular\" analysis for compound data. We consider the following metabolomics data, which has labels \"Meta\" \n",
    "#and additional mass and retention time information in the form {identifier,mass, retention time, label}:\n",
    "compoundsExample = [[\"cpd:C19691\", 325.2075, 10.677681, \"Meta\"], [\"cpd:C17905\", 594.2002, 8.727458, \"Meta\"],[\"cpd:C09921\", 204.0784, 12.3909445, \"Meta\"], \n",
    "                    [\"cpd:C18218\", 272.2356, 13.473582, \"Meta\"], [\"cpd:C14169\", 235.1573, 12.267084, \"Meta\"],[\"cpd:C14245\", 262.2296, 13.545572, \"Meta\"], \n",
    "                    [\"cpd:C09137\", 352.2615, 14.0554285, \"Meta\"], [\"cpd:C09674\", 296.1624, 12.147417, \"Meta\"], [\"cpd:C00449\", 276.1334, 11.004139, \"Meta\"], \n",
    "                    [\"cpd:C02999\", 364.1497, 12.147243, \"Meta\"], [\"cpd:C07915\", 309.194, 7.3625283, \"Meta\"],[\"cpd:C08760\", 496.2309, 8.7241125, \"Meta\"], \n",
    "                    [\"cpd:C14549\", 276.0972, 11.078914, \"Meta\"], [\"cpd:C20533\", 601.3378, 12.75722, \"Meta\"], [\"cpd:C20790\", 212.1051, 7.127666, \"Meta\"], \n",
    "                    [\"cpd:C09137\", 352.2613, 12.869867, \"Meta\"], [\"cpd:C17648\", 400.2085, 10.843841, \"Meta\"], [\"cpd:C07807\", 240.1471, 0.48564285, \"Meta\"], \n",
    "                    [\"cpd:C08564\", 324.0948, 10.281, \"Meta\"], [\"cpd:C19426\", 338.2818, 13.758765, \"Meta\"], [\"cpd:C02943\", 468.3218, 14.263261, \"Meta\"], \n",
    "                    [\"cpd:C04882\", 1193.342, 14.707576, \"Meta\"]]\n",
    "\n",
    "compoundsExampleKEGG = KEGGAnalysis(compoundsExample, FilterSignificant=True, AnalysisType='Molecular')\n",
    "\n",
    "ExportEnrichmentReport(compoundsExampleKEGG, AppendString='compoundsExampleKEGG', OutputDirectory=EnrichmentOutputDirectory + 'KEGGAnalysis/')\n",
    "\n",
    "#We can carry out multiomics data analysis. We consider the following simple example:\n",
    "multiOmicsData = [[\"C6orf57\", \"Protein\"], [\"CD46\", \"Protein\"], [\"DHX58\", \"Protein\"], [\"HMGB3\", \"RNA\"], [\"HMGB3\", \"Protein\"], \n",
    "                    [\"MAP3K5\", \"Protein\"], [\"NFKB2\", \"RNA\"], [\"NFKB2\", \"Protein\"], [\"NOS2\", \"RNA\"], [\"PYCARD\", \"RNA\"], [\"PYDC1\", \"Protein\"], \n",
    "                    [\"SSC5D\", \"Protein\"], [\"cpd:C19691\", 325.2075, 10.677681, \"Meta\"], [\"cpd:C17905\", 594.2002, 8.727458, \"Meta\"], \n",
    "                    [\"cpd:C09921\", 204.0784, 12.3909445, \"Meta\"], [\"cpd:C18218\", 272.2356, 13.473582, \"Meta\"], \n",
    "                    [\"cpd:C14169\", 235.1573, 12.267084, \"Meta\"], [\"cpd:C14245\", 262.2296, 13.545572, \"Meta\"], \n",
    "                    [\"cpd:C09137\", 352.2615, 14.0554285, \"Meta\"], [\"cpd:C09674\", 296.1624, 12.147417, \"Meta\"],\n",
    "                    [\"cpd:C00449\", 276.1334, 11.004139, \"Meta\"],[\"cpd:C02999\", 364.1497, 12.147243, \"Meta\"],\n",
    "                    [\"cpd:C07915\", 309.194, 7.3625283, \"Meta\"],[\"cpd:C08760\", 496.2309, 8.7241125, \"Meta\"],\n",
    "                    [\"cpd:C14549\", 276.0972, 11.078914, \"Meta\"],[\"cpd:C20533\", 601.3378, 12.75722, \"Meta\"], \n",
    "                    [\"cpd:C20790\", 212.1051, 7.127666, \"Meta\"], [\"cpd:C09137\", 352.2613, 12.869867, \"Meta\"],\n",
    "                    [\"cpd:C17648\", 400.2085, 10.843841, \"Meta\"], [\"cpd:C07807\", 240.1471, 0.48564285, \"Meta\"], \n",
    "                    [\"cpd:C08564\", 324.0948, 10.281, \"Meta\"], [\"cpd:C19426\", 338.2818, 13.758765, \"Meta\"], \n",
    "                    [\"cpd:C02943\", 468.3218, 14.263261, \"Meta\"], [\"cpd:C04882\", 1193.342, 14.707576, \"Meta\"]]\n",
    "\n",
    "#We can carry out \"Genomic\" and \"Molecular\" analysis concurrently by setting AnalysisType = \"All\":\n",
    "multiOmicsDataKEGG = KEGGAnalysis(multiOmicsData, AnalysisType='All', MultipleList=True, MultipleListCorrection='Automatic') \n",
    "\n",
    "ExportEnrichmentReport(multiOmicsDataKEGG, AppendString='multiOmicsDataKEGG', OutputDirectory=EnrichmentOutputDirectory + 'KEGGAnalysis/')\n",
    "\n",
    "#Let's consider an example from real protein data. We will use already clustered data, from the examples. Let's import the data:\n",
    "ExampleClusteringObject = ds.read(pio.os.path.join(pio.ConstantPyIOmicaExamplesDirectory, 'exampleClusteringObject_SLV_Delta_LAG1_Autocorr'))\n",
    "\n",
    "if not ExampleClusteringObject is None:\n",
    "    #We calculate the KEGGAnalysis for each group in each class:\n",
    "    ExampleClusteringObject = KEGGAnalysis(ExampleClusteringObject)\n",
    "\n",
    "    ExportEnrichmentReport(ExampleClusteringObject, AppendString='ExampleClusteringObject', OutputDirectory=EnrichmentOutputDirectory + 'KEGGAnalysis/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visibility Graph\n",
    "\n",
    "In this example we calculate the visibility graph of the mean signal of a clustered group. Both a circular as well as a horizontal layout are illustrated. Missing data are imputed to the mean of the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Domanskyi\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py:162: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return cls.__new__(cls, **d)\n",
      "C:\\Users\\Domanskyi\\AppData\\Roaming\\Python\\Python37\\site-packages\\networkx\\drawing\\nx_pylab.py:579: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if not cb.iterable(width):\n"
     ]
    }
   ],
   "source": [
    "# %load examplesVisibilityGraph.py\n",
    "\n",
    "from pyiomica.visualizationFunctions import makeVisibilityGraph, makeVisibilityBarGraph\n",
    "from pyiomica import dataStorage as ds\n",
    "from pyiomica.extendedDataFrame import DataFrame\n",
    "\n",
    "# Get an example of a clustering object from ConstantPyIOmicaExamplesDirectory\n",
    "ExampleClusteringObject = ds.read(pio.os.path.join(pio.ConstantPyIOmicaExamplesDirectory, 'exampleClusteringObject_SLV_Delta_LAG1_Autocorr'))\n",
    "\n",
    "# Use Group 1, Subgroup 2 data (chosen arbitrarily here)\n",
    "df_data = ExampleClusteringObject[1][2]['data']\n",
    "\n",
    "# Read intensities of all signals and the measurement time points (here positions)\n",
    "intensities, positions = df_data.values, df_data.columns.values\n",
    "\n",
    "# Normalize and aggregate the intensities to obtain one averaged signal\n",
    "normalized_intensities = DataFrame(data=intensities).imputeMissingWithMedian().apply(lambda data: pio.np.sum(data[data > 0.0]) / len(data), axis=0).values\n",
    "\n",
    "# Make normal visibility graphs on a 'cirle' and 'line' layouts\n",
    "makeVisibilityGraph(normalized_intensities, positions, 'results', 'circle_VG', layout='circle')\n",
    "makeVisibilityGraph(normalized_intensities, positions, 'results', 'line_VG', layout='line')\n",
    "\n",
    "# Make horizontal visibility graphs on a 'cirle' and 'line' layouts\n",
    "makeVisibilityGraph(normalized_intensities, positions, 'results', 'circle_VG', layout='circle', horizontal=True)\n",
    "makeVisibilityGraph(normalized_intensities, positions, 'results', 'line_VG', layout='line', horizontal=True)\n",
    "\n",
    "# Make horizontal and normal bar-style visibility graphs\n",
    "makeVisibilityBarGraph(normalized_intensities, positions, 'results', 'barVG')\n",
    "makeVisibilityBarGraph(normalized_intensities, positions, 'results', 'barVG', horizontal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended DataFrame\n",
    "\n",
    "In this example we demonstrate usage of some of the functions added to a standard DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      c1   c2   c3\n",
      "s1   0.5  2.0  3.0\n",
      "s2   0.0  2.0  6.0\n",
      "s3   7.0  3.0  0.0\n",
      "s4   2.0  2.0  8.0\n",
      "s5   1.0  NaN  NaN\n",
      "s6   6.0  0.0  0.0\n",
      "s7   0.0  0.0  0.0\n",
      "s8   3.0  3.0  3.1\n",
      "s9   3.0  2.0  NaN\n",
      "s10  4.0  NaN  4.0 \n",
      "\n",
      "Filtering out all-zero signals\n",
      "Removed  1 signals out of 10.\n",
      "Remaining  9 signals!\n",
      "      c1   c2   c3\n",
      "s1   0.5  2.0  3.0\n",
      "s2   0.0  2.0  6.0\n",
      "s3   7.0  3.0  0.0\n",
      "s4   2.0  2.0  8.0\n",
      "s5   1.0  NaN  NaN\n",
      "s6   6.0  0.0  0.0\n",
      "s8   3.0  3.0  3.1\n",
      "s9   3.0  2.0  NaN\n",
      "s10  4.0  NaN  4.0 \n",
      "\n",
      "Filtering out first time point zeros signals\n",
      "Removed  1 signals out of 9.\n",
      "Remaining  8 signals!\n",
      "      c1   c2   c3\n",
      "s1   0.5  2.0  3.0\n",
      "s3   7.0  3.0  0.0\n",
      "s4   2.0  2.0  8.0\n",
      "s5   1.0  NaN  NaN\n",
      "s6   6.0  0.0  0.0\n",
      "s8   3.0  3.0  3.1\n",
      "s9   3.0  2.0  NaN\n",
      "s10  4.0  NaN  4.0 \n",
      "\n",
      "\n",
      "Removing constant signals. Cutoff value is 0.2\n",
      "Removed  3 signals out of 8.\n",
      "Remaining  5 signals!\n",
      "     c1   c2   c3\n",
      "s1  0.5  2.0  3.0\n",
      "s3  7.0  3.0  0.0\n",
      "s4  2.0  2.0  8.0\n",
      "s6  6.0  0.0  0.0\n",
      "s9  3.0  2.0  NaN \n",
      "\n",
      "Filtering out low-quality signals (with more than 40.0% zero points)\n",
      "Removed  1 signals out of 5.\n",
      "Remaining  4 signals!\n",
      "     c1   c2   c3\n",
      "s1  0.5  2.0  3.0\n",
      "s3  7.0  3.0  0.0\n",
      "s4  2.0  2.0  8.0\n",
      "s9  3.0  2.0  NaN \n",
      "\n",
      "Filtering out low-quality signals (with more than 20.0% missing points)\n",
      "Removed  1 signals out of 4.\n",
      "Remaining  3 signals!\n",
      "     c1   c2   c3\n",
      "s1  0.5  2.0  3.0\n",
      "s3  7.0  3.0  0.0\n",
      "s4  2.0  2.0  8.0 \n",
      "\n",
      "      c1   c2   c3\n",
      "s1   0.5  2.0  3.0\n",
      "s3   7.0  3.0  0.0\n",
      "s4   2.0  2.0  8.0\n",
      "s11  2.0  0.0  6.0 \n",
      "\n",
      "Tagging 0.0 values with nan\n",
      "      c1   c2   c3\n",
      "s1   0.5  2.0  3.0\n",
      "s3   7.0  3.0  NaN\n",
      "s4   2.0  2.0  8.0\n",
      "s11  2.0  NaN  6.0 \n",
      "\n",
      "Tagging nan values with 0\n",
      "      c1   c2   c3\n",
      "s1   0.5  2.0  3.0\n",
      "s3   7.0  3.0  0.0\n",
      "s4   2.0  2.0  8.0\n",
      "s11  2.0  0.0  6.0 \n",
      "\n",
      "Tagging low values (<=1.0) with 1.0\n",
      "      c1   c2   c3\n",
      "s1   1.0  2.0  3.0\n",
      "s3   7.0  3.0  1.0\n",
      "s4   2.0  2.0  8.0\n",
      "s11  2.0  1.0  6.0 \n",
      "\n",
      "Z-score (Median-based) transforming box-cox transformed data\n",
      "           c1        c2        c3\n",
      "s1  -1.348979  0.000000 -0.404694\n",
      "s3   6.744897  1.348979 -0.944286\n",
      "s4   0.000000  0.000000  0.944286\n",
      "s11  0.000000 -1.348979  0.404694 \n",
      "\n",
      "Quantile normalizing signals...\n",
      "           c1        c2        c3\n",
      "s1   1.000000  2.833333  2.333333\n",
      "s3   6.000000  6.000000  1.000000\n",
      "s4   2.833333  2.833333  6.000000\n",
      "s11  2.833333  1.000000  3.333333 \n",
      "\n",
      "Box-cox transforming raw data\n",
      "Fitted lambda: 0.5773965145064796\n",
      "Fitted lambda: 0.5773965145064796\n",
      "Fitted lambda: 0.15965581414183105\n",
      "Fitted lambda: -1.5502665765966683\n",
      "Fitted lambda: -0.30524084134075496\n",
      "           c1        c2        c3\n",
      "s1   0.000000  0.852368  1.534071\n",
      "s3   2.282077  1.200850  0.000000\n",
      "s4   0.424800  0.424800  0.619372\n",
      "s11  0.624729  0.000000  1.380121 \n",
      "\n",
      "Normalizing signals to unity\n",
      "      c1        c2        c3\n",
      "s1   0.0  0.485689  0.874132\n",
      "s3   0.0 -0.428165 -0.903700\n",
      "s4   0.0  0.000000  1.000000\n",
      "s11  0.0 -0.637312  0.770606 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %load examplesExtendedDataFrame.py\n",
    "\n",
    "# Import Extended DataFrame from PyIOmica\n",
    "from pyiomica.extendedDataFrame import DataFrame\n",
    "\n",
    "# Create a simple data for testing and demonstration\n",
    "df_data = DataFrame(data=pio.np.array([[0.5,2,3],\n",
    "                                      [0,2,6],\n",
    "                                      [7,3,0],\n",
    "                                      [2,2,8],\n",
    "                                      [1,pio.np.nan,pio.np.nan],\n",
    "                                      [6,0,0],\n",
    "                                      [0,0,0],\n",
    "                                      [3,3,3.1],\n",
    "                                      [3,2,pio.np.nan],\n",
    "                                      [4,pio.np.nan,4]]).astype(float),\n",
    "                    index=['s1','s2','s3','s4','s5','s6','s7','s8','s9','s10'],\n",
    "                    columns=['c1', 'c2', 'c3'])\n",
    "print(df_data, '\\n')\n",
    "\n",
    "# Remove all-zero signals from the data\n",
    "df_data.filterOutAllZeroSignals(inplace=True)\n",
    "print(df_data, '\\n')\n",
    "\n",
    "# Remove firt-point-zero signals from the data\n",
    "df_data.filterOutReferencePointZeroSignals(inplace=True)\n",
    "print(df_data, '\\n')\n",
    "\n",
    "# Remove nearly-constant signals from the data\n",
    "df_data.removeConstantSignals(0.2, inplace=True)\n",
    "print(df_data, '\\n')\n",
    "\n",
    "# Remove signals with >75% non-zero points\n",
    "df_data.filterOutFractionZeroSignals(0.6, inplace=True)\n",
    "print(df_data, '\\n')\n",
    "\n",
    "# Remove signals with >75% non-zero points\n",
    "df_data.filterOutFractionMissingSignals(0.8, inplace=True)\n",
    "print(df_data, '\\n')\n",
    "\n",
    "# Add a signal with zeros\n",
    "df_data.loc['s11'] = [2,0,6]\n",
    "print(df_data, '\\n')\n",
    "\n",
    "# Replace any zeros with np.NaN (missing)\n",
    "df_data.tagValueAsMissing(inplace=True)\n",
    "print(df_data, '\\n')\n",
    "\n",
    "# Replace any missing values (np.NaN) with values\n",
    "df_data.tagMissingAsValue(value=0, inplace=True)\n",
    "print(df_data, '\\n')\n",
    "\n",
    "# Replace any values smaller than 'a' with 'b'\n",
    "df_data.tagLowValues(1., 1., inplace=True)\n",
    "print(df_data, '\\n') \n",
    "\n",
    "# Calculate modified zscore (median-based) of data\n",
    "df_data_zm = df_data.modifiedZScore()\n",
    "print(df_data_zm, '\\n') \n",
    "\n",
    "# Quantile normalize the data\n",
    "df_data_qn = df_data.quantileNormalize()\n",
    "print(df_data_qn, '\\n') \n",
    "\n",
    "# Box-cox transform data\n",
    "df_data_bc = df_data.boxCoxTransform()\n",
    "print(df_data_bc, '\\n')\n",
    "\n",
    "# Normalize signals to unity\n",
    "df_data_un = df_data.normalizeSignalsToUnity()\n",
    "print(df_data_un, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Expression Time Series Categorization\n",
    "In the example below we use SLV RNAseq data in the ConstantPyIOmicaExamplesDirectory directory to illustrate automatic time series categorization. The temporal trends, categorization and results are output in the corresponding results directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load examplesCategorization.py\n",
    "\n",
    "from pyiomica import categorizationFunctions as cf\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Unzip example data\n",
    "    with pio.zipfile.ZipFile(pio.os.path.join(pio.ConstantPyIOmicaExamplesDirectory, 'SLV.zip'), \"r\") as zipFile:\n",
    "        zipFile.extractall(path=pio.ConstantPyIOmicaExamplesDirectory)\n",
    "\n",
    "    # Process sample dataset SLV_Hourly1 \n",
    "    # Name of the fisrt data set \n",
    "    dataName = 'SLV_Hourly1TimeSeries'\n",
    "\n",
    "    # Define a directory name where results are be saved\n",
    "    saveDir = pio.os.path.join('results', dataName, '')\n",
    "\n",
    "    # Directory name where example data is (*.csv files)\n",
    "    dataDir = pio.os.path.join(pio.ConstantPyIOmicaExamplesDirectory, 'SLV')\n",
    "\n",
    "    # Read the example data into a DataFrame\n",
    "    df_data = pio.pd.read_csv(pio.os.path.join(dataDir, dataName + '.csv'), index_col=[0,1,2], header=0)\n",
    "\n",
    "    # Calculate time series categorization\n",
    "    cf.calculateTimeSeriesCategorization(df_data, dataName, saveDir, NumberOfRandomSamples = 10**5)\n",
    "\n",
    "    # Cluster the time series categorization results\n",
    "    cf.clusterTimeSeriesCategorization(dataName, saveDir)\n",
    "\n",
    "    # Make plots of the clustered time series categorization\n",
    "    cf.visualizeTimeSeriesCategorization(dataName, saveDir)\n",
    "\n",
    "\n",
    "    # Process sample dataset SLV_Hourly2, in the same way as SLV_Hourly1 above\n",
    "    dataName = 'SLV_Hourly2TimeSeries'\n",
    "    saveDir = pio.os.path.join('results', dataName, '')\n",
    "    dataDir = pio.os.path.join(pio.ConstantPyIOmicaExamplesDirectory, 'SLV')\n",
    "    df_data = pio.pd.read_csv(pio.os.path.join(dataDir, dataName + '.csv'), index_col=[0,1,2], header=0)\n",
    "    cf.calculateTimeSeriesCategorization(df_data, dataName, saveDir, NumberOfRandomSamples = 10**5)\n",
    "    cf.clusterTimeSeriesCategorization(dataName, saveDir)\n",
    "    cf.visualizeTimeSeriesCategorization(dataName, saveDir)\n",
    "\n",
    "\n",
    "    # Import data storage submodule to read results of processing sample datasets SLV_Hourly1 and SLV_Hourly2\n",
    "    from pyiomica import dataStorage as ds\n",
    "\n",
    "    # Use results from processing sample datasets SLV_Hourly1 and SLV_Hourly2 to calculate \"Delta\"\n",
    "    dataName = 'SLV_Hourly1TimeSeries'\n",
    "    df_data_processed_H1 = ds.read(dataName+'_df_data_transformed', hdf5fileName=pio.os.path.join('results',dataName,dataName+'.h5'))\n",
    "\n",
    "    dataName = 'SLV_Hourly2TimeSeries'\n",
    "    df_data_processed_H2 = ds.read(dataName+'_df_data_transformed', hdf5fileName=pio.os.path.join('results',dataName,dataName+'.h5'))\n",
    "\n",
    "    dataName = 'SLV_Delta'\n",
    "    saveDir = pio.os.path.join('results', dataName, '')\n",
    "    df_data = df_data_processed_H2.compareTwoTimeSeries(df_data_processed_H1, compareAllLevelsInIndex=False, mergeFunction=pio.np.median).fillna(0.)\n",
    "    cf.calculateTimeSeriesCategorization(df_data, dataName, saveDir, NumberOfRandomSamples = 10**5)\n",
    "    cf.clusterTimeSeriesCategorization(dataName, saveDir)\n",
    "    cf.visualizeTimeSeriesCategorization(dataName, saveDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proteomics Time Series Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load examplesProteomicsCategorization.py\n",
    "\n",
    "from pyiomica import categorizationFunctions as cf\n",
    "from pyiomica import dataStorage as ds\n",
    "from pyiomica import enrichmentAnalyses as ea\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Unzip example data\n",
    "    with pio.zipfile.ZipFile(pio.os.path.join(pio.ConstantPyIOmicaExamplesDirectory, 'SLV.zip'), \"r\") as zipFile:\n",
    "        zipFile.extractall(path=pio.ConstantPyIOmicaExamplesDirectory)\n",
    "\n",
    "    # Name of the fisrt data set \n",
    "    dataName = 'DailyTimeSeries_SLV_Protein'\n",
    "\n",
    "    # Define a directory name where results are be saved\n",
    "    saveDir = pio.os.path.join('results', dataName, '')\n",
    "\n",
    "    # Directory name where example data is (*.csv files)\n",
    "    dataDir = pio.os.path.join(pio.ConstantPyIOmicaExamplesDirectory, 'SLV')\n",
    "\n",
    "    # Read the example data into a DataFrame\n",
    "    df_data = pio.pd.read_csv(pio.os.path.join(dataDir, dataName + '.csv'), index_col=[0,1], header=0)\n",
    "\n",
    "    # Calculate time series categorization\n",
    "    cf.calculateTimeSeriesCategorization(df_data, dataName, saveDir, NumberOfRandomSamples = 10**5, referencePoint=2, preProcessData=False)\n",
    "\n",
    "    # Cluster the time series categorization results\n",
    "    cf.clusterTimeSeriesCategorization(dataName, saveDir)\n",
    "\n",
    "    # Make plots of the clustered time series categorization\n",
    "    cf.visualizeTimeSeriesCategorization(dataName, saveDir)\n",
    "\n",
    "    # Do enrichment GO and KEGG analysis on LAG1 results\n",
    "    LAG1 = ds.read('results/DailyTimeSeries_SLV_Protein/consolidatedGroupsSubgroups/DailyTimeSeries_SLV_Protein_LAG1_Autocorrelations_GroupsSubgroups')\n",
    "    ea.ExportEnrichmentReport(ea.GOAnalysis(LAG1), AppendString='GO_LAG1', OutputDirectory='results/DailyTimeSeries_SLV_Protein/')\n",
    "    ea.ExportEnrichmentReport(ea.KEGGAnalysis(LAG1), AppendString='KEGG_LAG1', OutputDirectory='results/DailyTimeSeries_SLV_Protein/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visibility Graph Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PyIOmica (https://github.com/gmiaslab/pyiomica by G. Mias Lab)\n",
      "graph type is: natural\n",
      "weight is: distance\n",
      "graph type is: natural\n",
      "weight is: distance\n",
      "graph type is: dual_natural\n",
      "weight is: distance\n",
      "direction type is: None\n",
      "the shortest path is: [0, 17]\n",
      "current cutoff is auto, the optimized percentiles cutoff is 0.000000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:579: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if not cb.iterable(width):\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import pyiomica as pio\n",
    "from pyiomica import visualizationFunctions\n",
    "from pyiomica import visibilityGraphCommunityDetection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### create time series\n",
    "np.random.seed(11)\n",
    "times = np.arange( 0, 2*np.pi, 0.35)\n",
    "tp = list(range(len(times)))\n",
    "data = 5*np.cos(times) + 2*np.random.random(len(times))\n",
    "\n",
    "### plot time series\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.plot(tp,data)\n",
    "ax.set_title('Time Series', fontdict={'color': 'k'},fontsize=20)\n",
    "ax.set_xlabel('Times', fontsize=20)\n",
    "ax.set_ylabel('Signal intensity', fontsize=20)\n",
    "ax.set_xticks(tp)\n",
    "ax.set_xticklabels([str(item) for item in np.round(tp,2)],fontsize=20, rotation=0)\n",
    "ax.set_yticks([])\n",
    "\n",
    "fig.tight_layout()\n",
    "filename ='./A.eps'\n",
    "fig.savefig(filename, dpi=600)\n",
    "plt.close(fig)\n",
    "\n",
    "### plot weighted natural visibility graph, weight is  Euclidean distance\n",
    "g_nx_NVG, A_NVG = visibilityGraphCommunityDetection.createVisibilityGraph(data,tp,\"natural\", weight = 'distance')\n",
    "filename = './B.eps'\n",
    "visualizationFunctions.PlotNVGBarGraph_Dual(A_NVG, data, tp,fileName = filename,\n",
    "                                            title = 'Natural Visibility Graph',fontsize=20,figsize=(8,3))\n",
    "\n",
    "### plot reverse perspective weighted natural visibility graph, weight is  Euclidean distance\n",
    "g_nx_revNVG, A_revNVG = visibilityGraphCommunityDetection.createVisibilityGraph(-data,tp,\"natural\", weight = 'distance')\n",
    "filename = './C.eps'\n",
    "visualizationFunctions.PlotNVGBarGraph_Dual(A_revNVG, -data, tp,fileName = filename,\n",
    "                                            title='Reverse perspective Natural Visibility Graph',fontsize=20,figsize=(8,3))\n",
    "\n",
    "### plot dual perspective natural visibility graph, weight is Euclidean distance\n",
    "g_nx_dualNVG, A_dualNVG = visibilityGraphCommunityDetection.createVisibilityGraph(data,tp,\"dual_natural\", \n",
    "                                                                                  weight = 'distance', withsign=True)\n",
    "filename = './D.eps'\n",
    "visualizationFunctions.PlotNVGBarGraph_Dual(A_dualNVG, data, tp,fileName=filename,\n",
    "                                            title='Dual perspective Natural Visibility Graph',fontsize=20,figsize=(10,4))\n",
    "\n",
    "### plot line layout dual perspective natural visibility graph with community structure, weight is Euclidean distance\n",
    "communities = visibilityGraphCommunityDetection.communityDetectByPathLength(g_nx_dualNVG, direction = None, cutoff='auto')\n",
    "com = (communities, g_nx_dualNVG)\n",
    "visualizationFunctions.makeVisibilityGraph(data, tp, './', 'E', layout='line',communities=com, \n",
    "                       level=0.8,figsize = (10,6), extension='.eps')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
